{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.svm import SVC\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6325 #number of records in file\n",
    "s = 2000 #desired sample size\n",
    "filename = \"train.csv\"\n",
    "skip = sorted(random.sample(xrange(n),n-s))\n",
    "df_train_sample = pd.read_csv(filename, skiprows=skip, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.000000000000000000e+00</th>\n",
       "      <th>7.122828847711242667e-04</th>\n",
       "      <th>1.423987452924897062e-03</th>\n",
       "      <th>2.134535857390711718e-03</th>\n",
       "      <th>2.843351189810218362e-03</th>\n",
       "      <th>3.549857948940669979e-03</th>\n",
       "      <th>4.253482507915815579e-03</th>\n",
       "      <th>4.953653579984939985e-03</th>\n",
       "      <th>5.649802682351916933e-03</th>\n",
       "      <th>6.341364597737685245e-03</th>\n",
       "      <th>...</th>\n",
       "      <th>-7.027777833283280727e-03</th>\n",
       "      <th>-6.341364597729205049e-03</th>\n",
       "      <th>-5.649802682343052496e-03</th>\n",
       "      <th>-4.953653579975694776e-03</th>\n",
       "      <th>-4.253482507906193068e-03</th>\n",
       "      <th>-3.549857948941927219e-03</th>\n",
       "      <th>-2.843351189811149909e-03</th>\n",
       "      <th>-2.134535857391314968e-03</th>\n",
       "      <th>-1.423987452925169197e-03</th>\n",
       "      <th>-7.122828847710639850e-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020292</td>\n",
       "      <td>0.141777</td>\n",
       "      <td>0.275296</td>\n",
       "      <td>0.111601</td>\n",
       "      <td>0.224555</td>\n",
       "      <td>0.226531</td>\n",
       "      <td>0.062487</td>\n",
       "      <td>0.259656</td>\n",
       "      <td>-0.077982</td>\n",
       "      <td>-0.092875</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043492</td>\n",
       "      <td>0.095030</td>\n",
       "      <td>0.080447</td>\n",
       "      <td>0.104674</td>\n",
       "      <td>-0.004612</td>\n",
       "      <td>0.013853</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>-0.091339</td>\n",
       "      <td>-0.091172</td>\n",
       "      <td>-0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004376</td>\n",
       "      <td>0.013978</td>\n",
       "      <td>0.019232</td>\n",
       "      <td>0.023490</td>\n",
       "      <td>0.025136</td>\n",
       "      <td>0.024229</td>\n",
       "      <td>0.021665</td>\n",
       "      <td>0.017912</td>\n",
       "      <td>0.011754</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021485</td>\n",
       "      <td>-0.027345</td>\n",
       "      <td>-0.031900</td>\n",
       "      <td>-0.034985</td>\n",
       "      <td>-0.036230</td>\n",
       "      <td>-0.035834</td>\n",
       "      <td>-0.033799</td>\n",
       "      <td>-0.030010</td>\n",
       "      <td>-0.024691</td>\n",
       "      <td>-0.018381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038217</td>\n",
       "      <td>0.084984</td>\n",
       "      <td>0.093411</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>0.077482</td>\n",
       "      <td>0.061309</td>\n",
       "      <td>0.053731</td>\n",
       "      <td>0.054602</td>\n",
       "      <td>0.057732</td>\n",
       "      <td>0.064238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004686</td>\n",
       "      <td>-0.011227</td>\n",
       "      <td>-0.016656</td>\n",
       "      <td>-0.020634</td>\n",
       "      <td>-0.022666</td>\n",
       "      <td>-0.022613</td>\n",
       "      <td>-0.020479</td>\n",
       "      <td>-0.016436</td>\n",
       "      <td>-0.011126</td>\n",
       "      <td>-0.004705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.010536</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.018704</td>\n",
       "      <td>0.020736</td>\n",
       "      <td>0.019504</td>\n",
       "      <td>0.012633</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>-0.010927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>-0.000515</td>\n",
       "      <td>-0.008925</td>\n",
       "      <td>-0.015868</td>\n",
       "      <td>-0.012429</td>\n",
       "      <td>-0.011004</td>\n",
       "      <td>-0.012790</td>\n",
       "      <td>-0.009779</td>\n",
       "      <td>-0.010296</td>\n",
       "      <td>-0.001233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014672</td>\n",
       "      <td>0.030505</td>\n",
       "      <td>0.033381</td>\n",
       "      <td>0.041119</td>\n",
       "      <td>0.043278</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.044791</td>\n",
       "      <td>0.047787</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.049644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028221</td>\n",
       "      <td>-0.027865</td>\n",
       "      <td>-0.027728</td>\n",
       "      <td>-0.026717</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>-0.023367</td>\n",
       "      <td>-0.020023</td>\n",
       "      <td>-0.016340</td>\n",
       "      <td>-0.013982</td>\n",
       "      <td>-0.008613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 88200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.000000000000000000e+00  7.122828847711242667e-04  \\\n",
       "0                  0.020292                  0.141777   \n",
       "1                  0.004376                  0.013978   \n",
       "2                  0.038217                  0.084984   \n",
       "3                  0.000392                  0.010536   \n",
       "4                  0.014672                  0.030505   \n",
       "\n",
       "   1.423987452924897062e-03  2.134535857390711718e-03  \\\n",
       "0                  0.275296                  0.111601   \n",
       "1                  0.019232                  0.023490   \n",
       "2                  0.093411                  0.094486   \n",
       "3                  0.016760                  0.018704   \n",
       "4                  0.033381                  0.041119   \n",
       "\n",
       "   2.843351189810218362e-03  3.549857948940669979e-03  \\\n",
       "0                  0.224555                  0.226531   \n",
       "1                  0.025136                  0.024229   \n",
       "2                  0.077482                  0.061309   \n",
       "3                  0.020736                  0.019504   \n",
       "4                  0.043278                  0.044334   \n",
       "\n",
       "   4.253482507915815579e-03  4.953653579984939985e-03  \\\n",
       "0                  0.062487                  0.259656   \n",
       "1                  0.021665                  0.017912   \n",
       "2                  0.053731                  0.054602   \n",
       "3                  0.012633                  0.005153   \n",
       "4                  0.044791                  0.047787   \n",
       "\n",
       "   5.649802682351916933e-03  6.341364597737685245e-03  \\\n",
       "0                 -0.077982                 -0.092875   \n",
       "1                  0.011754                  0.004436   \n",
       "2                  0.057732                  0.064238   \n",
       "3                  0.000507                 -0.010927   \n",
       "4                  0.049341                  0.049644   \n",
       "\n",
       "             ...              -7.027777833283280727e-03  \\\n",
       "0            ...                              -0.043492   \n",
       "1            ...                              -0.021485   \n",
       "2            ...                              -0.004686   \n",
       "3            ...                               0.005375   \n",
       "4            ...                              -0.028221   \n",
       "\n",
       "   -6.341364597729205049e-03  -5.649802682343052496e-03  \\\n",
       "0                   0.095030                   0.080447   \n",
       "1                  -0.027345                  -0.031900   \n",
       "2                  -0.011227                  -0.016656   \n",
       "3                  -0.000515                  -0.008925   \n",
       "4                  -0.027865                  -0.027728   \n",
       "\n",
       "   -4.953653579975694776e-03  -4.253482507906193068e-03  \\\n",
       "0                   0.104674                  -0.004612   \n",
       "1                  -0.034985                  -0.036230   \n",
       "2                  -0.020634                  -0.022666   \n",
       "3                  -0.015868                  -0.012429   \n",
       "4                  -0.026717                  -0.024923   \n",
       "\n",
       "   -3.549857948941927219e-03  -2.843351189811149909e-03  \\\n",
       "0                   0.013853                   0.000293   \n",
       "1                  -0.035834                  -0.033799   \n",
       "2                  -0.022613                  -0.020479   \n",
       "3                  -0.011004                  -0.012790   \n",
       "4                  -0.023367                  -0.020023   \n",
       "\n",
       "   -2.134535857391314968e-03  -1.423987452925169197e-03  \\\n",
       "0                  -0.091339                  -0.091172   \n",
       "1                  -0.030010                  -0.024691   \n",
       "2                  -0.016436                  -0.011126   \n",
       "3                  -0.009779                  -0.010296   \n",
       "4                  -0.016340                  -0.013982   \n",
       "\n",
       "   -7.122828847710639850e-04  \n",
       "0                  -0.013201  \n",
       "1                  -0.018381  \n",
       "2                  -0.004705  \n",
       "3                  -0.001233  \n",
       "4                  -0.008613  \n",
       "\n",
       "[5 rows x 88200 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train_sample = pd.read_csv(\"train.csv\", nrows=1000, header=None)\n",
    "df_test = pd.read_csv(\"test.csv\", header=None)\n",
    "df_test.drop(df_test.columns[[0]], axis=1, inplace=True)\n",
    "Y_train = df_train_sample.iloc[:,-1]\n",
    "df_train_sample.drop(df_train_sample.columns[[-1]], axis=1, inplace=True)\n",
    "df_train_sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, y_train, y_validate = ms.train_test_split(df_train_sample, Y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "LR_pred = LR.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, y_train)\n",
    "RF_pred = RF.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier()\n",
    "MLP.fit(X_train, y_train)\n",
    "MLP_pred = MLP.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "KNN.fit(X_train, y_train)\n",
    "KNN_pred = KNN.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "SV = SVC()\n",
    "SV.fit(X_train, y_train)\n",
    "SV_pred = SV.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, actual):\n",
    "    return (np.sum(predictions == actual) / float(len(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(pred1, pred2):\n",
    "    a = np.loadtxt(pred1, skiprows=1, usecols=1, delimiter=',')\n",
    "    b = np.loadtxt(pred2, skiprows=1, usecols=1, delimiter=',')\n",
    "    acc = accuracy(a, b)\n",
    "    del a\n",
    "    del b\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objfilesim(obj, f):\n",
    "    a = np.loadtxt(f, skiprows=1, usecols=1, delimiter=',')\n",
    "    acc = accuracy(obj, a)\n",
    "    del a\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9925\n",
      "0.6875\n",
      "0.995\n",
      "0.905\n",
      "0.29\n"
     ]
    }
   ],
   "source": [
    "print accuracy(LR_pred, y_validate)\n",
    "print accuracy(RF_pred, y_validate)\n",
    "print accuracy(MLP_pred, y_validate)\n",
    "print accuracy(KNN_pred, y_validate)\n",
    "print accuracy(SV_pred, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_test_pred = LR.predict(df_test)\n",
    "KNN_test_pred = KNN.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_test_pred = RF.predict(df_test)\n",
    "SV_test_pred = SV.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i) + \",\" + str(int(p)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file('lrpred.csv', LR_test_pred)\n",
    "write_to_file('knnpred.csv', KNN_test_pred)\n",
    "write_to_file('rfpred.csv', RF_test_pred)\n",
    "write_to_file('svpred.csv', SV_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715\n",
      "0.715\n"
     ]
    }
   ],
   "source": [
    "print similarity('phil.csv', 'lrpred.csv')\n",
    "print objfilesim(LR_test_pred, 'phil.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_convert_zeros(filename, predictions, cls, arr):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            if i in arr:\n",
    "                f.write(str(i) + \",\" + str(int(cls)) + \"\\n\")\n",
    "            else:\n",
    "                f.write(str(i) + \",\" + str(int(p)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rws = np.where(~df_test.any(axis=1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_convert_zeros('knn5.csv', KNN_test_pred, 5, rws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
